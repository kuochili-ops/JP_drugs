import streamlit as st
import pdfplumber
import pandas as pd
import requests
import re
import time
import io
from urllib.parse import quote
from bs4 import BeautifulSoup

# --- 1. è¨­å®šå€åŸŸ ---
AZURE_KEY = "9JDF24qrsW8rXiYmChS17yEPyNRI96nNXXqEKn5CyI6ql6iYcTOFJQQJ99BLAC3pKaRXJ3w3AAAbACOGVYVU"
AZURE_ENDPOINT = "https://api.cognitive.microsofttranslator.com"
AZURE_REGION = "eastasia"

# --- 2. ç¿»è­¯èˆ‡å°ç…§æ ¸å¿ƒé‚è¼¯ (åš´æ ¼åŸ·è¡Œ Azure å„ªå…ˆ) ---

def get_english_name_logic(jp_name):
    """
    é‚è¼¯ï¼š1. Azure ç¿»è­¯ -> 2. å¤±æ•—å‰‡ KEGG çˆ¬èŸ²
    """
    if not jp_name or str(jp_name).lower() == 'none':
        return "N/A", "Skip"

    # --- Step 1: Azure ç¿»è­¯ ---
    try:
        clean_ja = re.split(r'[\(\n\sï¼ˆ]', str(jp_name))[0].strip()
        url = f"{AZURE_ENDPOINT.strip('/')}/translate?api-version=3.0&from=ja&to=en"
        headers = {
            'Ocp-Apim-Subscription-Key': AZURE_KEY,
            'Ocp-Apim-Subscription-Region': AZURE_REGION,
            'Content-type': 'application/json; charset=utf-8'
        }
        res = requests.post(url, headers=headers, json=[{'text': clean_ja}], timeout=8)
        if res.status_code == 200:
            en_res = res.json()[0]['translations'][0]['text']
            if en_res and len(en_res) > 2:
                return en_res, "Azure"
    except:
        pass

    # --- Step 2: KEGG çˆ¬èŸ² (Azure æ²’æ‹¿åˆ°çµæœæ™‚) ---
    try:
        search_kw = re.split(r'[\(\n\sï¼ˆ]', str(jp_name))[0].strip()
        search_url = f"https://www.kegg.jp/medicus-bin/search_drug?search_keyword={quote(search_kw)}"
        r_s = requests.get(search_url, timeout=10)
        codes = re.findall(r'japic_code=(\d+)', r_s.text + r_s.url)
        if codes:
            jid = codes[0].zfill(8)
            ri = requests.get(f"https://www.kegg.jp/medicus-bin/japic_med?id={jid}")
            ri.encoding = ri.apparent_encoding
            soup = BeautifulSoup(ri.text, 'html.parser')
            th = soup.find('th', string=re.compile(r'æ¬§æ–‡ä¸€èˆ¬å'))
            if th and th.find_next_sibling('td'):
                return th.find_next_sibling('td').get_text(strip=True), "KEGG"
    except:
        pass

    return "[ç¿»è­¯å¤±æ•—]", "None"

# --- 3. è§£æå‡½å¼ (ä¿®æ­£æ¼æŠ“ 506 é …çš„å•é¡Œ) ---

def parse_full_medicine_pdf(file):
    all_data = []
    cat = "æœªçŸ¥é¡åˆ¥"
    
    with pdfplumber.open(file) as pdf:
        for page in pdf.pages:
            text = page.extract_text() or ""
            # 1. å‹•æ…‹åˆ¤å®šé¡åˆ¥ (æ ¹æ“šé é¢æ¨™é¡Œ)
            if "(1)" in text or "ã‚«ãƒ†ã‚´ãƒªA" in text: cat = "Cat A (æœ€å„ªå…ˆ)"
            elif "(2)" in text or "ã‚«ãƒ†ã‚´ãƒªB" in text: cat = "Cat B (å„ªå…ˆ)"
            elif "(3)" in text or "ã‚«ãƒ†ã‚´ãƒªC" in text: cat = "Cat C (ç©©å®šç¢ºä¿)"

            # --- æ ¸å¿ƒé‚è¼¯ï¼šæ¨¡ç³Šæ¨¡å¼æƒæ ---
            # åŒ¹é…è¦å¾‹ï¼šè¡Œé¦–æˆ–å­—ä¸²ä¸­å‡ºç¾ (å†…|æ³¨|å¤–)ï¼Œå¾Œè·Ÿ 3 ä½æ•¸å­—ï¼Œå¾Œè·Ÿä¸€æ®µæ—¥æ–‡å­—å…ƒ
            # é€™å€‹æ­£å‰‡è¡¨é”å¼æœƒæ•ç²æ‰€æœ‰ã€Œé•·å¾—åƒè—¥å“åˆ—ã€çš„æ–‡å­—ï¼Œä¸ç®¡å®ƒæ˜¯ä¸æ˜¯åœ¨è¡¨æ ¼è£¡
            pattern = re.compile(r'(å†…|æ³¨|å¤–)\s*(\d{3})\s*([^\s\d\t]+)')
            
            # æˆ‘å€‘å°‡æ•´é æ–‡å­—æŒ‰è¡Œè™•ç†ï¼Œä¸¦é€²è¡Œæ·±åº¦æ¸…æ´—
            lines = text.split('\n')
            for l in lines:
                l = l.strip()
                # æ’é™¤æ¨™é¡Œåˆ—
                if "æˆåˆ†å" in l or "è–¬æ•ˆåˆ†é¡" in l: continue
                
                # åŸ·è¡ŒåŒ¹é…
                matches = pattern.findall(l)
                for m in matches:
                    route, code, name = m
                    name = name.strip()
                    
                    # éæ¿¾æ‰å¤ªçŸ­æˆ–ç„¡æ„ç¾©çš„å­—å…ƒ
                    if len(name) < 2: continue
                    
                    # æª¢æŸ¥é‡è¤‡ (éå¸¸é‡è¦ï¼Œå› ç‚ºé€™æœƒæŠ“åˆ°è¡¨æ ¼å…§çš„æ–‡å­—)
                    if not any(d['æˆåˆ†æ—¥æ–‡å'] == name for d in all_data):
                        all_data.append({
                            "é¡åˆ¥": cat,
                            "çµ¦è—¥æ–¹å¼": route,
                            "ç”¨é€”é¡åˆ¥": code,
                            "æˆåˆ†æ—¥æ–‡å": name
                        })

    # æœ€çµ‚æ ¡å°ï¼šå¦‚æœæŠ“åˆ°çš„æ•¸é‡é‚„æ˜¯ä¸å°ï¼Œå¯èƒ½æ˜¯å› ç‚ºæœ‰äº›æˆåˆ†åä¸­é–“å¸¶æœ‰ç©ºæ ¼
    # æˆ‘å€‘å¯ä»¥å¢åŠ ä¸€çµ„æ›´å¯¬é¬†çš„åŒ¹é…é‚è¼¯
    return pd.DataFrame(all_data)
# --- 4. Streamlit UI ä»‹é¢ ---
st.set_page_config(layout="wide", page_title="å®‰å®šç¢ºä¿é†«è—¥å“ 506é …è§£æ")
st.title("ğŸ’Š å®‰å®šç¢ºä¿é†«è—¥å“å…¨é‡è§£æå·¥å…·")
st.write("è§£æé‚è¼¯ï¼šPDF è¡¨æ ¼+æ–‡å­—æƒæ (506é …) -> Azure å„ªå…ˆç¿»è­¯ -> KEGG å‚™æ´")

f = st.file_uploader("è«‹ä¸Šå‚³ PDF (000785498.pdf)", type=['pdf'])

if f:
    if 'raw_df' not in st.session_state:
        with st.spinner("æ­£åœ¨æå– 506 é …æˆåˆ†æ¸…å–®..."):
            # å‘¼å«ä¿®æ­£å¾Œçš„å‡½å¼å
            st.session_state.raw_df = parse_full_medicine_pdf(f)
    
    df = st.session_state.raw_df
    st.success(f"âœ… æˆåŠŸæå– {len(df)} é …æˆåˆ†ï¼")
    st.dataframe(df, use_container_width=True)

    if st.button("ğŸš€ é–‹å§‹å…¨é‡å°ç…§ (Azure + KEGG)"):
        final_list = []
        bar = st.progress(0)
        status = st.empty()
        
        for i, row in df.iterrows():
            jp_name = row["æˆåˆ†æ—¥æ–‡å"]
            status.text(f"è™•ç†é€²åº¦ ({i+1}/{len(df)}): {jp_name}")
            
            # åŸ·è¡Œç¿»è­¯é‚è¼¯
            en_name, source = get_english_name_logic(jp_name)
            
            final_list.append({
                "é¡åˆ¥": row["é¡åˆ¥"],
                "çµ¦è—¥æ–¹å¼": row["çµ¦è—¥æ–¹å¼"],
                "ç”¨é€”é¡åˆ¥": row["ç”¨é€”é¡åˆ¥"],
                "æˆåˆ†æ—¥æ–‡å": jp_name,
                "æˆåˆ†è‹±æ–‡å": en_name,
                "ç¿»è­¯ä¾†æº": source
            })
            bar.progress((i + 1) / len(df))
            
            # ç·©è¡
            if i % 15 == 0: time.sleep(0.1)
            
        res_df = pd.DataFrame(final_list)
        st.success("ğŸ‰ å…¨é‡å°ç…§å®Œæˆï¼")
        st.dataframe(res_df, use_container_width=True)
        
        # ä¸‹è¼‰ Excel
        out = io.BytesIO()
        with pd.ExcelWriter(out, engine='xlsxwriter') as writer:
            res_df.to_excel(writer, index=False)
        st.download_button("ğŸ“¥ ä¸‹è¼‰å…¨è§£æ Excel å ±å‘Š", out.getvalue(), "Medicine_Full_Report.xlsx")
