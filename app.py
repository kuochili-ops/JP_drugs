import streamlit as st
import pandas as pd
import requests
import io

def fetch_and_fill_kegg_data(input_df):
    # --- 1. å®šç¾©æ‚¨çš„æª”æ¡ˆæ¬„ä½åç¨± ---
    # æ ¹æ“šæ‚¨çš„æª”æ¡ˆé è¦½ï¼Œæ¬„ä½åˆ†åˆ¥æ˜¯ 'æˆåˆ†å (æ—¥)', 'æˆåˆ†å (è‹±)', 'KEGG_ID'
    target_col = 'æˆåˆ†å (æ—¥)'
    eng_col = 'æˆåˆ†å (è‹±)'
    id_col = 'KEGG_ID'

    if target_col not in input_df.columns:
        st.error(f"æ‰¾ä¸åˆ°æ¬„ä½ '{target_col}'ï¼Œè«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼ã€‚")
        return None

    # --- 2. å¾ KEGG ä¸‹è¼‰å°ç…§è¡¨ ---
    st.info("æ­£åœ¨é€£ç·šè‡³ KEGG è³‡æ–™åº«...")
    url = "https://rest.kegg.jp/list/dr_ja"
    try:
        response = requests.get(url, timeout=15)
        response.raise_for_status()
    except Exception as e:
        st.error(f"é€£ç·šå¤±æ•—: {e}")
        return None

    kegg_list = []
    for line in response.text.strip().split('\n'):
        parts = line.split('\t')
        if len(parts) < 2: continue
        
        k_id = parts[0].replace("dr:", "") # å–å¾— Dxxxxx
        full_info = parts[1] # å–å¾—åç¨±éƒ¨åˆ†
        
        # æ‹†è§£åç¨±ï¼šä¾‹å¦‚ "ã‚¢ã‚¹ãƒ”ãƒªãƒ³ (JAN); Aspirin (USP)"
        # æ‹¿ç¬¬ä¸€å€‹åˆ†è™Ÿå‰çš„å…§å®¹ï¼Œå†å»æ‰æ‹¬è™Ÿ
        jap_name_in_kegg = full_info.split(';')[0].split(' (')[0].strip()
        
        # æå–æ‹¬è™Ÿå…§çš„è‹±æ–‡å
        eng_name_in_kegg = ""
        if "(" in full_info and ")" in full_info:
            eng_name_in_kegg = full_info[full_info.rfind("(")+1 : full_info.rfind(")")]
        
        kegg_list.append({
            target_col: jap_name_in_kegg, 
            'REF_ID': k_id, 
            'REF_ENG': eng_name_in_kegg
        })

    ref_df = pd.DataFrame(kegg_list).drop_duplicates(target_col)

    # --- 3. åˆä½µèˆ‡å¡«è£œ ---
    # ä½¿ç”¨å·¦åˆä½µï¼Œå°‡æŠ“åˆ°çš„åƒè€ƒè³‡æ–™æ ¹æ“šã€Œæˆåˆ†å (æ—¥)ã€å°é½Š
    merged = pd.merge(input_df, ref_df, on=target_col, how='left')

    # å¦‚æœåŸæœ¬çš„ ID æˆ– è‹±æ–‡åæ˜¯ç©ºçš„ï¼Œå°±å¡«å…¥å¾ KEGG æŸ¥åˆ°çš„è³‡æ–™
    merged[id_col] = merged[id_col].fillna(merged['REF_ID'])
    merged[eng_col] = merged[eng_col].fillna(merged['REF_ENG'])

    # ç§»é™¤æš«å­˜æ¬„ä½
    result = merged.drop(columns=['REF_ID', 'REF_ENG'])
    return result

# --- Streamlit ä»‹é¢ ---
st.title("ğŸ’Š KEGG è—¥å“è³‡æ–™è£œé½Šå·¥å…·")
st.write("é‡å°ã€Šæ—¥æœ¬é†«å­¸æœƒæ¨è–¦å¿…è¦è—¥å“æ¸…å–®ã€‹è‡ªå‹•å¡«è£œç©ºç¼ºçš„ KEGG_ID èˆ‡ è‹±æ–‡å")

uploaded_file = st.file_uploader("è«‹ä¸Šå‚³æ‚¨çš„ CSV æª”æ¡ˆ", type=['csv'])

if uploaded_file:
    # è®€å– CSV
    df = pd.read_csv(uploaded_file)
    
    st.subheader("åŸå§‹è³‡æ–™é è¦½ (å‰5ç­†)")
    st.dataframe(df.head())

    if st.button("é–‹å§‹åŸ·è¡Œè‡ªå‹•è£œé½Š"):
        with st.spinner('æ¯”å°ä¸­ï¼Œè«‹ç¨å€™...'):
            final_df = fetch_and_fill_kegg_data(df)
            
            if final_df is not None:
                st.success("è™•ç†å®Œæˆï¼")
                
                # é¡¯ç¤ºçµ±è¨ˆï¼šè£œé½Šäº†å¤šå°‘ç­†
                filled_count = final_df['KEGG_ID'].count() - df['KEGG_ID'].count()
                st.write(f"ğŸ’¡ æœ¬æ¬¡æˆåŠŸç‚º {filled_count} å€‹é …ç›®è£œé½Šäº†è³‡è¨Šã€‚")
                
                st.subheader("è£œé½Šå¾Œçš„å®Œæ•´çµæœ")
                st.dataframe(final_df)

                # æä¾›ä¸‹è¼‰
                output = io.BytesIO()
                final_df.to_csv(output, index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰æ›´æ–°å¾Œçš„ CSV æª”æ¡ˆ",
                    data=output.getvalue(),
                    file_name="KEGG_Updated_List.csv",
                    mime="text/csv"
                )
