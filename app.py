import streamlit as st
import pandas as pd
import re
from urllib.parse import quote

def generate_official_links(ja_name):
    if not ja_name or pd.isna(ja_name):
        return "N/A", "N/A"
    
    # æ¸…æ´—ï¼šç§»é™¤æ‹¬è™Ÿå‚™è¨» (å¦‚ãƒ–ãƒ©ãƒ³ãƒ‰å)
    clean_ja = re.sub(r'[\(\ï¼ˆ].*?[\)\ï¼‰]', '', str(ja_name)).strip()
    
    # 1. ç”Ÿæˆ Google æœå°‹é€£çµ (ä¾æ“šæ‚¨çš„ç™¼ç¾ï¼šæˆåˆ†å + japic)
    google_search_url = f"https://www.google.com/search?q={quote(clean_ja + ' japic')}"
    
    # 2. ç”Ÿæˆ KEGG Medicus ç›´æ¥æœå°‹é€£çµ (æ—¥æœ¬è—¥å…¸å®˜æ–¹ä»‹é¢)
    kegg_medicus_url = f"https://www.kegg.jp/medicus-bin/search_medicus?search_string={quote(clean_ja)}&type=drug"
    
    return google_search_url, kegg_medicus_url

# --- UI ä»‹é¢ ---
st.set_page_config(layout="wide")
st.title("ğŸ” 505é …è—¥å“ï¼šå®˜æ–¹è³‡æ–™åº«å¿«é€Ÿæ ¸å°å·¥å…·")
st.markdown(f"æ ¹æ“šæ‚¨çš„ç™¼ç¾ï¼šç›´æ¥é€£çµè‡³ [JAPIC/KEGG](https://www.kegg.jp/) ç²å– 100% æº–ç¢ºçš„ JAN/INN è‹±æ–‡åã€‚")

f = st.file_uploader("ä¸Šå‚³æ‚¨ç›®å‰çš„ CSV", type=['csv'])

if f:
    df = pd.read_csv(f)
    # æ¸…ç†èˆŠçš„ç„¡ç”¨æ¬„ä½
    df = df.loc[:, ~df.columns.str.contains('^Unnamed|ä¾†æº|æˆåˆ†è‹±æ–‡å')]
    
    if st.button("ğŸš€ ç”Ÿæˆå®˜æ–¹å°ç…§é€£çµ"):
        links = df['æˆåˆ†æ—¥æ–‡å'].apply(generate_official_links)
        df['Googleå®˜æ–¹æœå°‹'] = [x[0] for x in links]
        df['KEGGç›´æ¥æ ¸å°'] = [x[1] for x in links]
        
        st.success("âœ… é€£çµå·²ç”Ÿæˆï¼è«‹é»æ“Šé€£çµç²å–æœ€æ­£ç¢ºçš„è‹±æ–‡åã€‚")
        
        # ä½¿ç”¨ Streamlit çš„ link é¡¯ç¤ºæ–¹å¼è®“ä½¿ç”¨è€…å¥½é»æ“Š
        st.dataframe(
            df,
            column_config={
                "Googleå®˜æ–¹æœå°‹": st.column_config.LinkColumn("Google Search"),
                "KEGGç›´æ¥æ ¸å°": st.column_config.LinkColumn("KEGG Official")
            },
            use_container_width=True
        )
        
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è¼‰å¸¶æœ‰å®˜æ–¹é€£çµçš„å·¥ä½œè¡¨", csv, "Medicine_Check_Links.csv")
