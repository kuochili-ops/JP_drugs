import streamlit as st
import pandas as pd
import requests
import io
import re

# 1. åŸºç¤å·¥å…·å‡½æ•¸ï¼šåƒ…ç”¨æ–¼ã€Œæ¯”å°æ™‚ã€çš„æ¸…æ´—ï¼Œä¸å½±éŸ¿åŸå§‹é¡¯ç¤º
def clean_for_match(text):
    if not isinstance(text, str): return ""
    # è½‰åŠå½¢
    text = text.translate(str.maketrans(
        'ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï¼ˆï¼‰',
        '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ()'
    ))
    # ç§»é™¤è—¥å…¸æ¨™è¨» (æ¯”å°ç”¨)
    text = re.sub(r'\(JP\d+.*?\)', '', text)
    text = re.sub(r'\(USP.*?\)', '', text)
    text = re.sub(r'\(NF.*?\)', '', text)
    # ç§»é™¤ â€» å’Œ * è™Ÿè¨»è¨˜
    text = re.sub(r'[â€»\*]\d+', '', text)
    # è™•ç† L/D å‰ç¶´ç¬¦è™Ÿèˆ‡ç©ºç™½
    text = text.replace('ï¼', '-').replace(' ', '').replace('ã€€', '')
    return text.strip()

# 2. æ ¸å¿ƒæ™ºæ…§æ¯”å°é‚è¼¯
def smart_match(search_name, kegg_ref):
    cleaned_input = clean_for_match(search_name)
    if not cleaned_input: return None, None
    
    # å„ªå…ˆç´š 1: æ¸…æ´—å¾Œå®Œå…¨ä¸€è‡´
    for ref in kegg_ref:
        if cleaned_input == ref['cleaned_name']:
            return ref['id'], ref['eng']

    # å„ªå…ˆç´š 2: åŒ…å«æ¯”å°
    for ref in kegg_ref:
        if cleaned_input in ref['cleaned_name']:
            return ref['id'], ref['eng']

    # å„ªå…ˆç´š 3: è¤‡æ–¹æ‹†è§£ (ãƒ»)
    if 'ãƒ»' in cleaned_input:
        parts = [p for p in cleaned_input.split('ãƒ»') if p]
        for ref in kegg_ref:
            if all(part in ref['cleaned_name'] for part in parts):
                return ref['id'], ref['eng']
    
    return None, None

def fetch_and_fill_kegg_data_final(input_df):
    target_col = 'æˆåˆ†å (æ—¥)'
    eng_col = 'æˆåˆ†å (è‹±)'
    id_col = 'KEGG_ID'

    # ä¸‹è¼‰ KEGG å°ç…§è¡¨
    url = "https://rest.kegg.jp/list/dr_ja"
    try:
        response = requests.get(url, timeout=20)
        response.raise_for_status()
    except:
        st.error("ç„¡æ³•é€£ç·šè‡³ KEGG è³‡æ–™åº«ã€‚")
        return None

    # é è™•ç† KEGG è³‡æ–™
    kegg_ref = []
    for line in response.text.strip().split('\n'):
        parts = line.split('\t')
        if len(parts) < 2: continue
        d_id = "dr_ja:" + parts[0].replace("dr:", "")
        full_info = parts[1]
        
        # æå–æ‹¬è™Ÿå…§çš„è‹±æ–‡å (é€šå¸¸æ˜¯æœ€å¾Œä¸€å€‹æ‹¬è™Ÿ)
        eng_match = re.search(r'\(([^)]+)\)$', full_info)
        eng_name = eng_match.group(1) if eng_match else ""
        
        kegg_ref.append({
            'id': d_id,
            'cleaned_name': clean_for_match(full_info),
            'eng': eng_name
        })

    # åŸ·è¡Œè£œé½Š
    progress_bar = st.progress(0)
    total_rows = len(input_df)
    
    for i, row in input_df.iterrows():
        # è‹¥ ID ç‚ºç©ºæ‰è£œ
        if pd.isna(row.get(id_col)) or str(row.get(id_col)).strip() in ["", "nan"]:
            found_id, found_eng = smart_match(row[target_col], kegg_ref)
            if found_id:
                input_df.at[i, id_col] = found_id
                # è‹¥è‹±æ–‡åç‚ºç©ºæ‰è£œ
                if pd.isna(row.get(eng_col)) or str(row.get(eng_col)).strip() == "":
                    input_df.at[i, eng_col] = found_eng
        
        progress_bar.progress((i + 1) / total_rows)
    
    return input_df

# --- 3. Streamlit UI ---
st.set_page_config(page_title="è—¥å“æ¸…å–®è‡ªå‹•è£œé½Š", layout="wide")
st.title("ğŸ’Š è—¥å“æ¸…å–®è‡ªå‹•è£œé½Š (é«˜ç›¸å®¹æ€§ç‰ˆ)")
st.markdown("""
### åŒ¹é…è¦å‰‡èªªæ˜ï¼š
1. **ä¿ç•™è—¥å…¸æ¨™è¨»**ï¼šç¨‹å¼æœƒè­˜åˆ¥ä½†ã€Œä¸æœƒåˆªé™¤ã€æ‚¨åŸå§‹è³‡æ–™ä¸­çš„ `(JP18)` ç­‰å…§å®¹ã€‚
2. **è‡ªå‹•éæ¿¾è¨»è¨˜**ï¼šæ¯”å°æ™‚è‡ªå‹•å¿½ç•¥ `â€»1`, `â€»2` ç­‰ç¬¦è™Ÿã€‚
3. **è¤‡æ–¹èˆ‡ç•°æ§‹é«”æ”¯æ´**ï¼šç²¾ç¢ºè™•ç† `ãƒ»` åˆ†éš”çš„æˆåˆ†åŠ `L-`, `D-` å‰ç¶´ã€‚
""")

uploaded_file = st.file_uploader("ä¸Šå‚³ CSV æª”æ¡ˆ (æ¬„ä½éœ€åŒ…å« 'æˆåˆ†å (æ—¥)')", type=['csv'])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.write("### åŸå§‹è³‡æ–™é è¦½")
    st.dataframe(df.head(5))

    if st.button("é–‹å§‹æ™ºæ…§è£œé½Š"):
        initial_missing = df['KEGG_ID'].isna().sum()
        with st.spinner("æ­£åœ¨æª¢ç´¢ä¸¦æ¯”å°è³‡æ–™..."):
            result_df = fetch_and_fill_kegg_data_final(df.copy())
            
            if result_df is not None:
                final_missing = result_df['KEGG_ID'].isna().sum()
                filled_count = initial_missing - final_missing
                
                st.success("è™•ç†å®Œç•¢ï¼")
                
                # æ•¸æ“šé¢æ¿
                c1, c2, c3 = st.columns(3)
                c1.metric("æˆåŠŸè£œé½Š", f"{filled_count} é …")
                c2.metric("å°šæœªé…å°", f"{final_missing} é …")
                c3.metric("ç¸½ç­†æ•¸", f"{len(result_df)} ç­†")
                
                if final_missing > 0:
                    with st.expander("ğŸ” æª¢è¦–æœªé…å°é …ç›®"):
                        st.table(result_df[result_df['KEGG_ID'].isna()][['æˆåˆ†å (æ—¥)', 'æˆåˆ†å (è‹±)']])
                
                st.subheader("å®Œæ•´çµæœ")
                st.dataframe(result_df)
                
                # ä¸‹è¼‰
                csv_buffer = io.BytesIO()
                result_df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
                st.download_button("ğŸ“¥ ä¸‹è¼‰æ›´æ–°å¾Œçš„ CSV", data=csv_buffer.getvalue(), file_name="KEGG_Updated_List.csv")
