import streamlit as st
import pandas as pd
import requests
import re
import uuid

# --- 1. é é¢åŸºæœ¬é…ç½® ---
st.set_page_config(page_title="è—¥å“æ¸…å–®è£œå®Œèˆ‡ç¿»è­¯ç³»çµ±", layout="wide")

# ã€è¨­å®šå€ã€‘è«‹å¡«å…¥æ‚¨çš„ Azure ç¿»è­¯é‡‘é‘°è³‡è¨Š
AZURE_KEY = "æ‚¨çš„_AZURE_SUBSCRIPTION_KEY"
AZURE_ENDPOINT = "https://api.cognitive.microsofttranslator.com"
AZURE_LOCATION = "æ‚¨çš„_å€åŸŸ" # ä¾‹å¦‚: eastasia

# --- 2. KEGG å­—å…¸æ¨¡çµ„ï¼šç²¾ç¢ºæŠ“å–åˆ†è™Ÿå¾Œçš„è‹±æ–‡å ---
@st.cache_data(ttl=3600)
def get_kegg_master_dict():
    url = "https://rest.kegg.jp/list/drug_ja/"
    kegg_map = {}
    try:
        response = requests.get(url, timeout=20)
        if response.status_code == 200:
            for line in response.text.strip().split('\n'):
                parts = line.split('\t')
                if len(parts) >= 2:
                    k_id = parts[0].replace('dr:', '').strip()
                    full_text = parts[1]
                    
                    # è™•ç†æ ¼å¼: æ—¥æ–‡å (JP18); English name (JP18)
                    if ';' in full_text:
                        # A. æŠ“å–åˆ†è™Ÿå¾Œçš„è‹±æ–‡éƒ¨åˆ†ä¸¦ç§»é™¤æ‹¬è™Ÿæ¨™è¨˜
                        en_part = full_text.split(';')[1].strip()
                        en_name = re.sub(r'[\(\ï¼ˆ].*?[\)\ï¼‰]', '', en_part).strip()
                        
                        # B. æŠ“å–åˆ†è™Ÿå‰çš„æ—¥æ–‡éƒ¨åˆ†ä½œç‚ºæ¯”å° Key
                        jp_part = full_text.split(';')[0].strip()
                        jp_name = re.sub(r'[\(\ï¼ˆ].*?[\)\ï¼‰]', '', jp_part).strip()
                        
                        kegg_map[jp_name] = {"id": k_id, "en": en_name}
        return kegg_map
    except Exception as e:
        st.error(f"KEGG å­—å…¸ä¸‹è¼‰å¤±æ•—: {e}")
        return {}

# --- 3. Azure ç¿»è­¯æ¨¡çµ„ï¼šå¼·åŠ›æ¸…æ´—æ–‡æœ¬è§£æ±º [é€£ç·šå¤±æ•—] ---
def translate_via_azure(text):
    if not text or pd.isna(text) or str(text).strip() == "" or text == "N/A":
        return ""

    # ã€æ ¸å¿ƒä¿®æ­£ã€‘ç§»é™¤æ‰€æœ‰æ›è¡Œç¬¦èˆ‡å¤šé¤˜ç©ºæ ¼ï¼Œè®“é•·æ–‡æœ¬é€£è²«
    clean_text = str(text).replace('\n', ' ').replace('\r', ' ').strip()
    clean_text = re.sub(r'\s+', ' ', clean_text)

    path = '/translate'
    url = AZURE_ENDPOINT + path
    headers = {
        'Ocp-Apim-Subscription-Key': AZURE_KEY,
        'Ocp-Apim-Subscription-Region': AZURE_LOCATION,
        'Content-type': 'application/json',
        'X-ClientTraceId': str(uuid.uuid4())
    }
    params = {'api-version': '3.0', 'from': 'ja', 'to': 'zh-Hant'}
    body = [{'text': clean_text}]

    try:
        # å¢åŠ  timeout åˆ° 20 ç§’ï¼Œç¢ºä¿é•·æ–‡æœ¬ç¿»è­¯æœ‰è¶³å¤ æ™‚é–“
        r = requests.post(url, params=params, headers=headers, json=body, timeout=20)
        if r.status_code == 200:
            return r.json()[0]['translations'][0]['text']
        else:
            return f"[APIéŒ¯èª¤ {r.status_code}]"
    except Exception as e:
        return f"[ç¿»è­¯è¶…æ™‚/é€£ç·šå¤±æ•—]"

# --- 4. Streamlit UI æµç¨‹ ---
st.title("ğŸ§ª è—¥å“æ¸…å–®å…¨è‡ªå‹•è™•ç† (KEGG å°ç…§ + ç†ç”±ç¿»è­¯)")

# é è¼‰å­—å…¸
kegg_lookup = get_kegg_master_dict()

uploaded_file = st.file_uploader("1. ä¸Šå‚³ CSV æª”æ¡ˆ", type="csv")

if uploaded_file:
    # è®€å–æª”æ¡ˆ
    df = pd.read_csv(uploaded_file)
    st.write("æª”æ¡ˆé è¦½ï¼š")
    st.dataframe(df.head(3))

    if st.button("2. é–‹å§‹å…¨è‡ªå‹•åŸ·è¡Œ (ID æ¯”å° + ç†ç”±ç¿»è­¯)"):
        # åˆå§‹åŒ–æˆ–æ¸…ç©ºèˆŠæ¬„ä½
        df['KEGG_ID'] = "Searching..."
        df['æˆåˆ†å (è‹±)'] = "N/A"
        df['ç¿»è­¯ç†ç”±'] = ""

        progress_bar = st.progress(0)
        status_text = st.empty()
        
        total_rows = len(df)
        
        for i, row in df.iterrows():
            # A. è™•ç†æˆåˆ†åä¸¦æ¯”å° KEGG
            raw_jp = str(row['æˆåˆ†å (æ—¥)']).strip()
            # ç§»é™¤æ‹¬è™Ÿå…§å®¹é€²è¡Œç²¾æº–æ¯”å° (å¦‚: æ°´å’Œç‰©)
            clean_jp = re.sub(r'[ï¼ˆ\(].*?[ï¼‰\)]', '', raw_jp).strip()
            
            if clean_jp in kegg_lookup:
                df.at[i, 'KEGG_ID'] = kegg_lookup[clean_jp]['id']
                df.at[i, 'æˆåˆ†å (è‹±)'] = kegg_lookup[clean_jp]['en']
            else:
                df.at[i, 'KEGG_ID'] = "Not Found"
            
            # B. ç¿»è­¯é•·æ–‡æœ¬ (é¸å®šç†ç”±æ‘˜è¦)
            # é€™è£¡å‡è¨­ CSV æ¬„ä½åç¨±ç‚º 'é¸å®šç†ç”±æ‘˜è¦'
            reason_jp = row.get('é¸å®šç†ç”±æ‘˜è¦', '')
            df.at[i, 'ç¿»è­¯ç†ç”±'] = translate_via_azure(reason_jp)
            
            # æ›´æ–°é€²åº¦æ¢
            if i % 5 == 0 or i == total_rows - 1:
                progress_bar.progress((i + 1) / total_rows)
                status_text.text(f"æ­£åœ¨è™•ç†ç¬¬ {i+1}/{total_rows} ç­†: {clean_jp}")

        status_text.success("âœ… è™•ç†å®Œæˆï¼")
        
        # é¡¯ç¤ºçµæœ (èª¿æ•´æ¬„ä½é †åº)
        display_cols = ['å€åˆ†', 'æˆåˆ†å (æ—¥)', 'æˆåˆ†å (è‹±)', 'KEGG_ID', 'ç¿»è­¯ç†ç”±']
        existing_cols = [c for c in display_cols if c in df.columns]
        st.dataframe(df[existing_cols], use_container_width=True)

        # åŒ¯å‡º CSV (ä½¿ç”¨ sig ç¢ºä¿ Excel é–‹å•Ÿä¸äº‚ç¢¼)
        csv_data = df.to_csv(index=False, encoding="utf-8-sig")
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰æœ€çµ‚å®Œæ•´ CSV",
            data=csv_data,
            file_name="final_translated_med_list.csv",
            mime="text/csv"
        )
