import streamlit as st
import pandas as pd
import requests
import re
import uuid
import time

# --- 1. é é¢åŸºæœ¬é…ç½® ---
st.set_page_config(page_title="è—¥å“æ¸…å–®è£œå®Œèˆ‡ç¿»è­¯ç³»çµ±", layout="wide")

# ã€é‡è¦è¨­å®šã€‘è«‹ç¢ºä¿é€™è£¡çš„å€¼æ²’æœ‰å…¨å½¢ç©ºæ ¼æˆ–ä¸­æ–‡å­—
AZURE_KEY = "æ‚¨çš„_AZURE_SUBSCRIPTION_KEY" # 32ä½å…ƒé‡‘é‘°
AZURE_ENDPOINT = "https://api.cognitive.microsofttranslator.com"
AZURE_LOCATION = "eastasia" # å¿…é ˆç‚ºå°å¯«è‹±æ–‡ï¼Œä¾‹å¦‚ eastasia æˆ– global

# --- 2. KEGG å­—å…¸æ¨¡çµ„ ---
@st.cache_data(ttl=3600)
def get_kegg_master_dict():
    url = "https://rest.kegg.jp/list/drug_ja/"
    kegg_map = {}
    try:
        response = requests.get(url, timeout=20)
        if response.status_code == 200:
            for line in response.text.strip().split('\n'):
                parts = line.split('\t')
                if len(parts) >= 2:
                    k_id = parts[0].replace('dr:', 'dr_ja:').strip() # çµ±ä¸€æ ¼å¼
                    full_text = parts[1]
                    if ';' in full_text:
                        en_part = full_text.split(';')[1].strip()
                        en_name = re.sub(r'[\(\ï¼ˆ].*?[\)\ï¼‰]', '', en_part).strip()
                        jp_part = full_text.split(';')[0].strip()
                        jp_name = re.sub(r'[\(\ï¼ˆ].*?[\)\ï¼‰]', '', jp_part).strip()
                        kegg_map[jp_name] = {"id": k_id, "en": en_name}
        return kegg_map
    except Exception as e:
        return {"error": str(e)}

# --- 3. å¼·åŒ–ç‰ˆç¿»è­¯å‡½æ•¸ï¼šè§£æ±ºç·¨ç¢¼éŒ¯èª¤èˆ‡é•·æ–‡æœ¬è¶…æ™‚ ---
def translate_via_azure(text):
    if not text or pd.isna(text) or str(text).strip() == "" or text == "N/A":
        return ""

    # æ–‡æœ¬æ¸…æ´—
    clean_text = str(text).replace('\n', ' ').replace('\r', ' ').strip()
    clean_text = re.sub(r'\s+', ' ', clean_text)

    # å»ºç«‹ Header (åŠ ä¸Š str().strip() ç¢ºä¿ç„¡ç‰¹æ®Šå­—å…ƒ)
    try:
        headers = {
            'Ocp-Apim-Subscription-Key': str(AZURE_KEY).strip(),
            'Ocp-Apim-Subscription-Region': str(AZURE_LOCATION).strip(),
            'Content-type': 'application/json',
            'X-ClientTraceId': str(uuid.uuid4())
        }
    except UnicodeEncodeError:
        return "[è¨­å®šéŒ¯èª¤] è«‹æª¢æŸ¥ Azure Key æˆ– Region æ˜¯å¦åŒ…å«ä¸­æ–‡å­—æˆ–å…¨å½¢ç¬¦è™Ÿ"

    params = {'api-version': '3.0', 'from': 'ja', 'to': 'zh-Hant'}
    
    # é‡å°æ¥µé•·æ–‡æœ¬é€²è¡Œåˆ†æ®µè™•ç† (æ¯ 1000 å­—ä¸€æ®µ)
    chunks = [clean_text[i:i+1000] for i in range(0, len(clean_text), 1000)]
    translated_chunks = []

    for chunk in chunks:
        body = [{'text': chunk}]
        try:
            r = requests.post(f"{AZURE_ENDPOINT}/translate", params=params, headers=headers, json=body, timeout=30)
            if r.status_code == 200:
                translated_chunks.append(r.json()[0]['translations'][0]['text'])
            else:
                translated_chunks.append(f"[éŒ¯èª¤ {r.status_code}]")
        except:
            translated_chunks.append("[ç¿»è­¯è¶…æ™‚]")
        time.sleep(0.1) # é¿é–‹é »ç‡é™åˆ¶

    return "".join(translated_chunks)

# --- 4. Streamlit UI æµç¨‹ ---
st.title("ğŸ’Š è—¥å“æ¸…å–®å…¨è‡ªå‹•è™•ç†ç³»çµ±")

kegg_lookup = get_kegg_master_dict()
if "error" in kegg_lookup:
    st.error(f"KEGG å­—å…¸è¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šã€‚")

uploaded_file = st.file_uploader("1. ä¸Šå‚³ CSV æª”æ¡ˆ", type="csv")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.write("å·²è®€å–æª”æ¡ˆï¼Œé å‚™è™•ç†...")

    if st.button("2. é–‹å§‹å…¨è‡ªå‹•åŸ·è¡Œ"):
        # åˆå§‹åŒ–æ¬„ä½
        if 'KEGG_ID' not in df.columns: df['KEGG_ID'] = ""
        if 'æˆåˆ†å (è‹±)' not in df.columns: df['æˆåˆ†å (è‹±)'] = ""
        if 'ç¿»è­¯ç†ç”±' not in df.columns: df['ç¿»è­¯ç†ç”±'] = ""

        progress_bar = st.progress(0)
        status_text = st.empty()
        total = len(df)

        for i, row in df.iterrows():
            # A. KEGG å°ç…§
            jp_name_raw = str(row['æˆåˆ†å (æ—¥)']).strip()
            clean_jp = re.sub(r'[ï¼ˆ\(].*?[ï¼‰\)]', '', jp_name_raw).strip()
            
            if clean_jp in kegg_lookup:
                df.at[i, 'KEGG_ID'] = kegg_lookup[clean_jp]['id']
                df.at[i, 'æˆåˆ†å (è‹±)'] = kegg_lookup[clean_jp]['en']
            
            # B. ç¿»è­¯é•·æ–‡æœ¬æ‘˜è¦
            # å„ªå…ˆæœå°‹ 'é¸å®šç†ç”±æ‘˜è¦' æˆ– 'ç†ç”±' æ¬„ä½
            reason_col = 'é¸å®šç†ç”±æ‘˜è¦' if 'é¸å®šç†ç”±æ‘˜è¦' in df.columns else df.columns[-1]
            df.at[i, 'ç¿»è­¯ç†ç”±'] = translate_via_azure(row[reason_col])

            # æ›´æ–° UI
            if i % 5 == 0 or i == total - 1:
                progress_bar.progress((i + 1) / total)
                status_text.text(f"è™•ç†ä¸­ ({i+1}/{total}): {clean_jp}")

        status_text.success("âœ… ä»»å‹™å®Œæˆï¼")
        
        # é¡¯ç¤ºèˆ‡ä¸‹è¼‰
        st.dataframe(df, use_container_width=True)
        csv_out = df.to_csv(index=False, encoding="utf-8-sig")
        st.download_button("ğŸ“¥ ä¸‹è¼‰æœ€çµ‚ CSV", csv_out, "final_data.csv", "text/csv")
