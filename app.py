import streamlit as st
import pdfplumber
import pandas as pd
import re

# æ¨¡æ“¬æˆåˆ†è‹±æ–‡åå°ç…§è¡¨ (å»ºè­°å¾ŒçºŒæ“´å……ç‚ºå®Œæ•´ CSV)
EN_MAPPING = {
    "ãƒ¯ãƒ«ãƒ•ã‚¡ãƒªãƒ³ã‚«ãƒªã‚¦ãƒ ": "Warfarin Potassium",
    "ã‚·ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ³": "Cyclosporine",
    "ã‚¿ã‚¯ãƒ­ãƒªãƒ ã‚¹æ°´å’Œç‰©": "Tacrolimus Hydrate",
    "ãƒ—ãƒ­ãƒãƒ•ã‚©ãƒ¼ãƒ«": "Propofol",
    "ãƒŸãƒ€ã‚¾ãƒ©ãƒ ": "Midazolam",
    "ãƒ­ã‚¯ãƒ­ãƒ‹ã‚¦ãƒ è‡­åŒ–ç‰©": "Rocuronium Bromide",
    "ãƒ‰ãƒ‘ãƒŸãƒ³å¡©é…¸å¡©": "Dopamine Hydrochloride",
    "ã‚»ãƒ•ã‚¡ã‚¾ãƒªãƒ³ãƒŠãƒˆãƒªã‚¦ãƒ ": "Cefazolin Sodium",
    "ã‚¢ã‚»ãƒˆã‚¢ãƒŸãƒãƒ•ã‚§ãƒ³": "Acetaminophen",
    # ... ä¾æ­¤é¡æ¨
}

def parse_pdf(file):
    all_data = []
    current_category = "æœªçŸ¥é¡åˆ¥"
    
    with pdfplumber.open(file) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            # åµæ¸¬é¡åˆ¥æ¨™é¡Œ
            if "(1)" in text or "ã‚«ãƒ†ã‚´ãƒªA" in text:
                current_category = "ã‚«ãƒ†ã‚´ãƒª A (æœ€å„ªå…ˆ)"
            elif "(2)" in text or "ã‚«ãƒ†ã‚´ãƒªB" in text:
                current_category = "ã‚«ãƒ†ã‚´ãƒª B (å„ªå…ˆ)"
            elif "(3)" in text or "ã‚«ãƒ†ã‚´ãƒªC" in text:
                current_category = "ã‚«ãƒ†ã‚´ãƒª C (å®‰å®šç¢ºä¿)"

            tables = page.extract_tables()
            for table in tables:
                for row in table:
                    # éæ¿¾æ‰ç©ºè¡Œæˆ–æ¨™é¡Œè¡Œ
                    if not row or len(row) < 3: continue
                    
                    route = str(row[0]).strip().replace('\n', '')
                    class_no = str(row[1]).strip().replace('\n', '')
                    name_jp = str(row[2]).strip().replace('\n', '')
                    
                    # åªè™•ç†æœ‰çµ¦è—¥æ–¹å¼ç¬¦è™Ÿçš„åˆ—
                    if route in ['å†…', 'æ³¨', 'å¤–']:
                        name_en = EN_MAPPING.get(name_jp, "Searching...") # æ²’å°ç…§åˆ°çš„é¡¯ç¤ºé è¨­å€¼
                        
                        all_data.append({
                            "é¡åˆ¥": current_category,
                            "çµ¦è—¥æ–¹å¼": route,
                            "ç”¨é€”åˆ†é¡ç·¨è™Ÿ": class_no,
                            "æˆåˆ†æ—¥æ–‡å": name_jp,
                            "æˆåˆ†è‹±æ–‡å": name_en
                        })
    return pd.DataFrame(all_data)

# Streamlit ä»‹é¢
st.set_page_config(page_title="æ—¥æœ¬å®‰å®šç¢ºä¿é†«è—¥å“å°ç…§å·¥å…·", layout="wide")
st.title("ğŸ’Š å®‰å®šç¢ºä¿é†«è—¥å“æ¸…å–®æŠ“å–å™¨")
st.write("è«‹ä¸Šå‚³æ—¥æœ¬åšå‹çœç™¼ä½ˆçš„ã€Œå®‰å®šç¢ºä¿åŒ»è–¬å“ã€PDF æª”æ¡ˆä»¥é€²è¡Œè‡ªå‹•è§£æã€‚")

uploaded_file = st.file_uploader("é¸æ“‡ PDF æª”æ¡ˆ", type="pdf")

if uploaded_file is not None:
    with st.spinner('æ­£åœ¨è§£æ PDF è¡¨æ ¼ä¸­...'):
        df = parse_pdf(uploaded_file)
        
    if not df.empty:
        st.success(f"æˆåŠŸæŠ“å– {len(df)} é …æˆåˆ†ï¼")
        
        # ç¯©é¸å™¨
        cats = st.multiselect("ç¯©é¸é¡åˆ¥", options=df["é¡åˆ¥"].unique(), default=df["é¡åˆ¥"].unique())
        routes = st.multiselect("ç¯©é¸çµ¦è—¥æ–¹å¼", options=df["çµ¦è—¥æ–¹å¼"].unique(), default=df["çµ¦è—¥æ–¹å¼"].unique())
        
        filtered_df = df[(df["é¡åˆ¥"].isin(cats)) & (df["çµ¦è—¥æ–¹å¼"].isin(routes))]
        
        # è¼¸å‡ºè¡¨æ ¼
        st.dataframe(filtered_df, use_container_width=True)
        
        # ä¸‹è¼‰æŒ‰éˆ•
        csv = filtered_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ä¸‹è¼‰è§£æçµæœ (CSV)", csv, "medicine_list.csv", "text/csv")
    else:
        st.error("æœªèƒ½è­˜åˆ¥è¡¨æ ¼å…§å®¹ï¼Œè«‹æª¢æŸ¥ PDF æ ¼å¼ã€‚")
