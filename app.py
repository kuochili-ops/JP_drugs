import streamlit as st
import pandas as pd
import requests
import re
from urllib.parse import quote

# æ ¸å¿ƒï¼šç‰‡å‡åè½‰è‹±æ–‡æ‹¼éŸ³åŸºç¤è¡¨ (è§£æ±ºå¤§éƒ¨åˆ†è½‰æ›å•é¡Œ)
KATA_TO_EN = {
    'ã‚¢': 'a', 'ã‚¤': 'i', 'ã‚¦': 'u', 'ã‚¨': 'e', 'ã‚ª': 'o',
    'ã‚«': 'ka', 'ã‚­': 'ki', 'ã‚¯': 'ku', 'ã‚±': 'ke', 'ã‚³': 'ko',
    'ã‚µ': 'sa', 'ã‚·': 'shi', 'ã‚¹': 'su', 'ã‚»': 'se', 'ã‚½': 'so',
    'ã‚¿': 'ta', 'ãƒ': 'chi', 'ãƒ„': 'tsu', 'ãƒ†': 'te', 'ãƒˆ': 'to',
    'ãƒŠ': 'na', 'ãƒ‹': 'ni', 'ãƒŒ': 'nu', 'ãƒ': 'ne', 'ãƒ': 'no',
    'ãƒ': 'ha', 'ãƒ’': 'hi', 'ãƒ•': 'fu', 'ãƒ˜': 'he', 'ãƒ›': 'ho',
    'ãƒ': 'ma', 'ãƒŸ': 'mi', 'ãƒ ': 'mu', 'ãƒ¡': 'me', 'ãƒ¢': 'mo',
    'ãƒ¤': 'ya', 'ãƒ¦': 'yu', 'ãƒ¨': 'yo',
    'ãƒ©': 'ra', 'ãƒª': 'ri', 'ãƒ«': 'ru', 'ãƒ¬': 're', 'ãƒ­': 'ro',
    'ãƒ¯': 'wa', 'ãƒ³': 'n', 'ã‚¬': 'ga', 'ã‚®': 'gi', 'ã‚°': 'gu', 'ã‚²': 'ge', 'ã‚´': 'go',
    'ã‚¶': 'za', 'ã‚¸': 'ji', 'ã‚º': 'zu', 'ã‚¼': 'ze', 'ã‚¾': 'zo',
    'ãƒ€': 'da', 'ãƒ‚': 'ji', 'ãƒ…': 'zu', 'ãƒ‡': 'de', 'ãƒ‰': 'do',
    'ãƒ': 'ba', 'ãƒ“': 'bi', 'ãƒ–': 'bu', 'ãƒ™': 'be', 'ãƒœ': 'bo',
    'ãƒ‘': 'pa', 'ãƒ”': 'pi', 'ãƒ—': 'pu', 'ãƒš': 'pe', 'ãƒ': 'po',
    'ãƒ£': 'ya', 'ãƒ¥': 'yu', 'ãƒ§': 'yo', 'ãƒƒ': '', 'ãƒ¼': ''
}

# é¹½é¡èˆ‡å¾Œç¶´å°æ‡‰
SUFFIX_CLEAN = {
    "å¡©é…¸å¡©": " hydrochloride", "ç¡«é…¸å¡©": " sulfate", "ã‚«ãƒªã‚¦ãƒ ": " potassium",
    "ãƒŠãƒˆãƒªã‚¦ãƒ ": " sodium", "æ°´å’Œç‰©": " hydrate", "ãƒ•ãƒãƒ«é…¸å¡©": " fumarate"
}

def auto_translate(text):
    """ å¼•æ“1ï¼šé‚è¼¯ç¿»è­¯ (ä¸ä¾è³´è©åº«) """
    if not text: return ""
    # ç§»é™¤æ‹¬è™Ÿé›œè¨Š
    text = re.sub(r'[\(\ï¼ˆ].*?[\)\ï¼‰]', '', str(text)).strip()
    
    # è™•ç†é¹½é¡å¾Œç¶´åˆ†é›¢
    suffix_en = ""
    for ja, en in SUFFIX_CLEAN.items():
        if ja in text:
            suffix_en = en
            text = text.replace(ja, "")
            break
            
    # åŸ·è¡ŒéŸ³è­¯è½‰æ›
    res = "".join([KATA_TO_EN.get(char, char) for char in text])
    return res.capitalize() + suffix_en

def get_pubchem_standard(eng_name):
    """ å¼•æ“2ï¼šå¤–éƒ¨è³‡æºæ ¡æ­£ (å‘ PubChem é©—è­‰) """
    try:
        url = f"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/{quote(eng_name)}/synonyms/JSON"
        resp = requests.get(url, timeout=3)
        if resp.status_code == 200:
            return resp.json()['InformationList']['Information'][0]['Synonym'][0]
    except:
        pass
    return eng_name # æŸ¥ä¸åˆ°å°±ç”¨ç¿»è­¯å¥½çš„

def process_line(ja_name):
    # è™•ç†è¤‡åˆåŠ‘
    if 'ï½¥' in ja_name or 'ãƒ»' in ja_name:
        parts = re.split(r'[ï½¥ãƒ»]', ja_name)
        return " / ".join([get_pubchem_standard(auto_translate(p)) for p in parts])
    return get_pubchem_standard(auto_translate(ja_name))

# --- UI ---
st.title("ğŸŒ å¤–éƒ¨è³‡æº + é‚è¼¯ç¿»è­¯å™¨ (505é …å…¨è‡ªå‹•ç‰ˆ)")
st.write("æ­¤ç‰ˆæœ¬å„ªå…ˆä½¿ç”¨é‚è¼¯éŸ³è­¯ï¼Œå†ç”±å¤–éƒ¨æ•¸æ“šåº« PubChem é€²è¡Œåç¨±æ ¡æ­£ã€‚")

f = st.file_uploader("ä¸Šå‚³æœ€å¾Œä¸€ä»½ CSV", type=['csv'])

if f:
    df = pd.read_csv(f)
    if st.button("ğŸš€ å•Ÿå‹• 505 é …æƒæ (ä¸éœ€è©åº«)"):
        with st.spinner('å¼•æ“å•Ÿå‹•ä¸­...'):
            df['æˆåˆ†è‹±æ–‡å'] = df['æˆåˆ†æ—¥æ–‡å'].apply(process_line)
            df['ä¾†æº'] = "Auto_Logic_PubChem"
        st.success("âœ… è™•ç†å®Œæˆï¼")
        st.dataframe(df)
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è¼‰å…¨è‡ªå‹•å°æ‡‰ CSV", csv, "Medicine_Auto_Final.csv")
