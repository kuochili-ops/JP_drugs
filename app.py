import streamlit as st
import pandas as pd
import requests
import re
import uuid
import time

# --- 1. åŸºæœ¬é…ç½® ---
st.set_page_config(page_title="è—¥å“æ¸…å–®ç¿»è­¯è£œå®Œç³»çµ±", layout="wide")

# ã€å‹™å¿…æª¢æŸ¥ã€‘è«‹ç¢ºä¿é€™è£¡çš„è‹±æ–‡å­—æ¯å®Œå…¨æ­£ç¢ºï¼Œä¸è¦æœ‰ç©ºæ ¼
AZURE_KEY = "æ‚¨çš„_32ä½å…ƒé‡‘é‘°"
AZURE_ENDPOINT = "https://api.cognitive.microsofttranslator.com"
AZURE_LOCATION = "eastasia" # å¿…é ˆæ˜¯è‹±æ–‡å°å¯«ï¼Œä¾‹å¦‚ eastasia, southeastasia æˆ– global

# --- 2. KEGG å­—å…¸æ¨¡çµ„ (ç¢ºä¿ ID èˆ‡ è‹±æ–‡åæ­£ç¢º) ---
@st.cache_data(ttl=3600)
def get_kegg_master_dict():
    url = "https://rest.kegg.jp/list/drug_ja/"
    kegg_map = {}
    try:
        response = requests.get(url, timeout=30)
        if response.status_code == 200:
            for line in response.text.strip().split('\n'):
                parts = line.split('\t')
                if len(parts) >= 2:
                    k_id = parts[0].replace('dr:', 'dr_ja:').strip()
                    full_text = parts[1]
                    if ';' in full_text:
                        en_part = full_text.split(';')[1].strip()
                        en_name = re.sub(r'[\(\ï¼ˆ].*?[\)\ï¼‰]', '', en_part).strip()
                        jp_part = full_text.split(';')[0].strip()
                        jp_name = re.sub(r'[\(\ï¼ˆ].*?[\)\ï¼‰]', '', jp_part).strip()
                        kegg_map[jp_name] = {"id": k_id, "en": en_name}
        return kegg_map
    except Exception:
        return {}

# --- 3. å¼·åŠ›åˆ†æ®µç¿»è­¯å‡½æ•¸ (è§£æ±ºè¶…æ™‚æ ¸å¿ƒ) ---
def translate_via_azure_safe(text):
    if not text or pd.isna(text) or str(text).strip() == "":
        return ""

    # æ¸…æ´—æ–‡æœ¬ï¼šç§»é™¤æ›è¡Œä¸¦å£“ç¸®ç©ºæ ¼
    clean_text = str(text).replace('\n', ' ').replace('\r', ' ').strip()
    clean_text = re.sub(r'\s+', ' ', clean_text)

    # ã€ç­–ç•¥ã€‘å¦‚æœé•·åº¦è¶…é 500 å­—ï¼Œé€²è¡Œæ‹†åˆ†ç¿»è­¯ä»¥é˜² API è¶…æ™‚
    chunk_size = 500
    chunks = [clean_text[i:i+chunk_size] for i in range(0, len(clean_text), chunk_size)]
    
    headers = {
        'Ocp-Apim-Subscription-Key': str(AZURE_KEY).strip(),
        'Ocp-Apim-Subscription-Region': str(AZURE_LOCATION).strip(),
        'Content-type': 'application/json',
        'X-ClientTraceId': str(uuid.uuid4())
    }
    params = {'api-version': '3.0', 'from': 'ja', 'to': 'zh-Hant'}
    
    translated_result = []
    
    for chunk in chunks:
        body = [{'text': chunk}]
        try:
            # å°‡ timeout å¢åŠ åˆ° 60 ç§’ï¼Œç¢ºä¿é•·æ–‡æœ¬æœ‰è¶³å¤ æ™‚é–“é‹ç®—
            r = requests.post(f"{AZURE_ENDPOINT}/translate", params=params, headers=headers, json=body, timeout=60)
            if r.status_code == 200:
                translated_result.append(r.json()[0]['translations'][0]['text'])
            else:
                translated_result.append(f"[APIéŒ¯èª¤ {r.status_code}]")
        except Exception:
            translated_result.append("[ç¿»è­¯è¶…æ™‚/é€£ç·šå¤±æ•—]")
        
        # å¢åŠ çŸ­æš«å»¶é²ï¼Œé¿å…è«‹æ±‚éå¿«
        time.sleep(0.5)

    return "".join(translated_result)

# --- 4. Streamlit UI æµç¨‹ ---
st.title("ğŸ’Š é†«è—¥è³‡æ–™å…¨è‡ªå‹•è™•ç†ç³»çµ± (åˆ†æ®µè™•ç†ç‰ˆ)")

kegg_lookup = get_kegg_master_dict()

uploaded_file = st.file_uploader("1. ä¸Šå‚³ CSV æª”æ¡ˆ", type="csv")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    
    if st.button("2. é–‹å§‹å…¨è‡ªå‹•åŸ·è¡Œ (ID æ¯”å° + åˆ†æ®µç¿»è­¯ç†ç”±)"):
        # ç¢ºä¿ç›®æ¨™æ¬„ä½åˆå§‹åŒ–
        if 'KEGG_ID' not in df.columns: df['KEGG_ID'] = ""
        if 'æˆåˆ†å (è‹±)' not in df.columns: df['æˆåˆ†å (è‹±)'] = ""
        if 'ç¿»è­¯ç†ç”±' not in df.columns: df['ç¿»è­¯ç†ç”±'] = ""

        progress_bar = st.progress(0)
        status_text = st.empty()
        total = len(df)

        for i, row in df.iterrows():
            # A. KEGG ID èˆ‡ è‹±æ–‡åå°ç…§
            raw_jp = str(row['æˆåˆ†å (æ—¥)']).strip()
            clean_jp = re.sub(r'[ï¼ˆ\(].*?[ï¼‰\)]', '', raw_jp).strip()
            
            if clean_jp in kegg_lookup:
                df.at[i, 'KEGG_ID'] = kegg_lookup[clean_jp]['id']
                df.at[i, 'æˆåˆ†å (è‹±)'] = kegg_lookup[clean_jp]['en']
            else:
                df.at[i, 'KEGG_ID'] = "Not Found"

            # B. æ¡ç”¨ç†ç”±ç¿»è­¯ (åˆ†æ®µè™•ç†)
            # è‡ªå‹•åµæ¸¬æ¬„ä½ï¼šè‹¥ç„¡ã€Œé¸å®šç†ç”±æ‘˜è¦ã€å‰‡æŠ“æœ€å¾Œä¸€æ¬„
            reason_col = 'é¸å®šç†ç”±æ‘˜è¦' if 'é¸å®šç†ç”±æ‘˜è¦' in df.columns else df.columns[-1]
            df.at[i, 'ç¿»è­¯ç†ç”±'] = translate_via_azure_safe(row[reason_col])

            # C. æ›´æ–°é€²åº¦
            if i % 5 == 0 or i == total - 1:
                progress_bar.progress((i + 1) / total)
                status_text.text(f"æ­£åœ¨è™•ç† ({i+1}/{total}): {clean_jp}")

        status_text.success("âœ… å…¨éƒ¨è™•ç†å®Œæˆï¼")
        st.dataframe(df, use_container_width=True)

        # ä¸‹è¼‰æŒ‰éˆ• (ä½¿ç”¨ sig ç¢ºä¿ Excel é–‹å•Ÿä¸äº‚ç¢¼)
        csv_out = df.to_csv(index=False, encoding="utf-8-sig")
        st.download_button("ğŸ“¥ ä¸‹è¼‰æœ€çµ‚å®Œæˆç‰ˆ CSV", csv_out, "final_data.csv", "text/csv")
