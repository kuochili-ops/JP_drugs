import streamlit as st
import pandas as pd
import requests
import re
import uuid
import time

# --- 1. é é¢é…ç½® ---
st.set_page_config(page_title="è—¥å“æ¸…å–®è£œå®Œèˆ‡ç¿»è­¯ç³»çµ±", layout="wide")

# ã€è¨­å®šå€ã€‘è«‹å¡«å…¥æ‚¨çš„æ­£ç¢ºé‡‘é‘°
AZURE_KEY = "æ‚¨çš„_AZURE_SUBSCRIPTION_KEY"
AZURE_ENDPOINT = "https://api.cognitive.microsofttranslator.com"
AZURE_LOCATION = "æ‚¨çš„_å€åŸŸ" # ä¾‹å¦‚: eastasia

# --- 2. KEGG å­—å…¸æ¨¡çµ„ ---
@st.cache_data(ttl=3600)
def get_kegg_master_dict():
    url = "https://rest.kegg.jp/list/drug_ja/"
    kegg_map = {}
    try:
        response = requests.get(url, timeout=20)
        if response.status_code == 200:
            for line in response.text.strip().split('\n'):
                parts = line.split('\t')
                if len(parts) >= 2:
                    k_id = parts[0].replace('dr:', '').strip()
                    full_text = parts[1]
                    if ';' in full_text:
                        en_part = full_text.split(';')[1].strip()
                        en_name = re.sub(r'[\(\ï¼ˆ].*?[\)\ï¼‰]', '', en_part).strip()
                        jp_part = full_text.split(';')[0].strip()
                        jp_name = re.sub(r'[\(\ï¼ˆ].*?[\)\ï¼‰]', '', jp_part).strip()
                        kegg_map[jp_name] = {"id": k_id, "en": en_name}
        return kegg_map
    except Exception as e:
        st.error(f"KEGG ä¸‹è¼‰å¤±æ•—: {e}")
        return {}

# --- 3. å¼·åŒ–ç‰ˆç¿»è­¯å‡½æ•¸ï¼šè§£æ±ºè¶…æ™‚å•é¡Œ ---
def translate_via_azure(text):
    if not text or pd.isna(text) or str(text).strip() == "" or text == "N/A":
        return ""

    # æ¸…æ´—æ›è¡Œç¬¦è™Ÿï¼Œé€™æ˜¯é˜²æ­¢ API èª¤åˆ¤çš„é—œéµ
    clean_text = str(text).replace('\n', ' ').replace('\r', ' ').strip()
    clean_text = re.sub(r'\s+', ' ', clean_text)

    # å¦‚æœæ–‡æœ¬å¤ªé•·ï¼ˆè¶…é 1000 å­—ï¼‰ï¼Œæˆªæ–·æˆ–åˆ†æ®µè™•ç†ï¼ˆæ­¤è™•å…ˆæ¡é é˜²æ€§æˆªæ–·ï¼Œæˆ–ç›´æ¥å¢åŠ è¶…æ™‚ï¼‰
    if len(clean_text) > 4000:
        clean_text = clean_text[:4000]

    path = '/translate'
    url = AZURE_ENDPOINT + path
    headers = {
        'Ocp-Apim-Subscription-Key': AZURE_KEY,
        'Ocp-Apim-Subscription-Region': AZURE_LOCATION,
        'Content-type': 'application/json',
        'X-ClientTraceId': str(uuid.uuid4())
    }
    params = {'api-version': '3.0', 'from': 'ja', 'to': 'zh-Hant'}
    body = [{'text': clean_text}]

    # å˜—è©¦å¤šæ¬¡ç¿»è­¯ï¼Œé˜²æ­¢å¶ç™¼æ€§é€£ç·šä¸­æ–·
    for attempt in range(2): 
        try:
            # å°‡ timeout å¢åŠ åˆ° 45 ç§’ï¼Œè™•ç†è¶…é•·æ–‡æœ¬
            r = requests.post(url, params=params, headers=headers, json=body, timeout=45)
            if r.status_code == 200:
                return r.json()[0]['translations'][0]['text']
            elif r.status_code == 429: # Too Many Requests
                time.sleep(1) # ç­‰å¾…ä¸€ç§’é‡è©¦
                continue
            else:
                return f"[APIéŒ¯èª¤ {r.status_code}]"
        except (requests.exceptions.Timeout, requests.exceptions.ConnectionError):
            if attempt == 0:
                time.sleep(2)
                continue
            return "[ç¿»è­¯è¶…æ™‚/é€£ç·šå¤±æ•—]"
    return "[ç¿»è­¯å¤±æ•—]"

# --- 4. Streamlit UI ---
st.title("ğŸ’Š è—¥å“æ¸…å–®å…¨è‡ªå‹•è™•ç† (å¾é ­åˆ°å°¾ç‰ˆ)")

kegg_lookup = get_kegg_master_dict()

uploaded_file = st.file_uploader("1. ä¸Šå‚³å°å‡ºçš„ CSV æª”æ¡ˆ", type="csv")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„æ¬„ä½ï¼Œè‹¥æ²’æœ‰å‰‡æ ¹æ“šæ‚¨çš„å°å‡ºæª”é‡æ–°å®šä½
    target_col = 'é¸å®šç†ç”±æ‘˜è¦' if 'é¸å®šç†ç”±æ‘˜è¦' in df.columns else None
    
    if st.button("2. é–‹å§‹åŸ·è¡Œ (å°ç…§ ID + å®Œæ•´ç¿»è­¯ç†ç”±)"):
        # åˆå§‹åŒ–æ¬„ä½
        df['KEGG_ID'] = "Searching..."
        df['æˆåˆ†å (è‹±)'] = "N/A"
        df['ç¿»è­¯ç†ç”±'] = ""

        progress_bar = st.progress(0)
        status_text = st.empty()
        
        total_rows = len(df)
        
        for i, row in df.iterrows():
            # A. KEGG å°ç…§
            raw_jp = str(row['æˆåˆ†å (æ—¥)']).strip()
            clean_jp = re.sub(r'[ï¼ˆ\(].*?[ï¼‰\)]', '', raw_jp).strip()
            
            if clean_jp in kegg_lookup:
                df.at[i, 'KEGG_ID'] = kegg_lookup[clean_jp]['id']
                df.at[i, 'æˆåˆ†å (è‹±)'] = kegg_lookup[clean_jp]['en']
            else:
                df.at[i, 'KEGG_ID'] = "Not Found"

            # B. é¸å®šç†ç”±ç¿»è­¯
            if target_col:
                reason_jp = row[target_col]
                df.at[i, 'ç¿»è­¯ç†ç”±'] = translate_via_azure(reason_jp)
            
            # æ¯ 10 ç­†æ›´æ–°ä¸€æ¬¡é€²åº¦ï¼Œé¿å…ç•«é¢é–ƒçˆ
            if i % 10 == 0 or i == total_rows - 1:
                progress_bar.progress((i + 1) / total_rows)
                status_text.text(f"é€²åº¦: {i+1}/{total_rows} - æ­£åœ¨è™•ç†: {clean_jp}")

        status_text.success("âœ… ä»»å‹™å®Œæˆï¼")
        
        # é¡¯ç¤ºçµæœ (é¡¯ç¤ºä¸»è¦æ¬„ä½)
        show_cols = ['å€åˆ†', 'æˆåˆ†å (æ—¥)', 'æˆåˆ†å (è‹±)', 'KEGG_ID', 'ç¿»è­¯ç†ç”±']
        existing_show = [c for c in show_cols if c in df.columns]
        st.dataframe(df[existing_show], use_container_width=True)

        # æä¾›ä¸‹è¼‰
        csv_data = df.to_csv(index=False, encoding="utf-8-sig")
        st.download_button("ğŸ“¥ ä¸‹è¼‰æœ€çµ‚å®Œæˆç‰ˆ CSV", csv_data, "final_data.csv", "text/csv")
